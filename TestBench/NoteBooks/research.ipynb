{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#ffaa00; border-bottom: 2px dotted #ff00aa\" > Get the Test Names </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "abspath = Path('C:\\\\Users\\\\harkum\\\\Documents\\\\6311\\\\Software')\n",
    "os.chdir(abspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#00aaff; \"> Filter All the Test names and Dump to yaml file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import random\n",
    "import re \n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "def dump_test_names(path:Path):\n",
    "    DFT_tests = {}\n",
    "    for sh in ['Digital','Reference','Boost']:\n",
    "        sheet = 'raw_data/'+sh+'_data.csv'\n",
    "        data = pd.read_csv(sheet)\n",
    "        cols = []\n",
    "        for col in data.columns.to_list()[1:]:\n",
    "            #replace the space with \n",
    "            col = re.sub(' ','_', col.strip()) \n",
    "            #replace the special charecters with underscore '_'\n",
    "            col = re.sub('[!-\\/:-@[-`{-~]','_', col)\n",
    "            cols.append(col)\n",
    "        DFT_tests.update(\n",
    "            {\n",
    "               sh: cols\n",
    "            }\n",
    "        )\n",
    "\n",
    "    with open(path, 'w') as file :\n",
    "        yaml.dump({\"TestBench\":DFT_tests}, file)\n",
    "\n",
    "dump_test_names('TestBench/testscript_generate_config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#ff00aa; \"> Create Test Script with yaml file data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os \n",
    "\n",
    "def create_test_scripts(configFile:Path):\n",
    "    with open(configFile) as stream:\n",
    "        try:\n",
    "            tests = yaml.safe_load(stream).get('TestBench')\n",
    "            # create the directory for each page \n",
    "            for page in list(tests.keys()):\n",
    "                #if there is not directory for the page create one else pass \n",
    "                page_dir = os.path.join(os.getcwd(),f'TestBench/{page}')\n",
    "                if not(os.path.exists(page_dir)):\n",
    "                    os.mkdir(page_dir)\n",
    "                #if the directory exists create the test scripts \n",
    "                else:\n",
    "                    for test_name in tests.get(page):\n",
    "                        \n",
    "                        test_scripts_name = os.path.join(page_dir, f'{test_name}.py')\n",
    "                        if not(os.path.exists(test_scripts_name)):\n",
    "                            with open(test_scripts_name, 'w') as file:\n",
    "                                test_string = f'''\n",
    "class {test_name}:\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def {test_name}_testSetup(self):\n",
    "        pass \n",
    "    \n",
    "    def {test_name}_measurements(self,config: dict):\n",
    "        pass\n",
    "     \n",
    "    def {test_name}_evaluation(self,limits:dict):\n",
    "        return None           \n",
    "                                '''\n",
    "                                file.write(test_string)\n",
    "                        else:\n",
    "                            pass \n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "create_test_scripts('TestBench/testscript_generate_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test:\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def Test_testSetup(self):\n",
    "        pass \n",
    "    \n",
    "    def Test_measurements(self,config: dict):\n",
    "        pass\n",
    "     \n",
    "    def Test_evaluation(self,limits:dict)-> dict:\n",
    "        return {} \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
